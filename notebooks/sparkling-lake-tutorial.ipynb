{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Sparkling Lake with glm-py\n",
    "\n",
    "**This tutorial guides users through the process of setting up a model of \n",
    "Sparkling Lake using glm-py.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/AquaticEcoDynamics/glm-py/blob/main/notebooks/sparkling-lake-tutorial.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparkling Lake is an oligotrophic, northern temperate lake (89.7 ºN, 46.3 ºW) in Winconsin, USA. The lake is approximately 20m deep and covers a surface area of 0.638km<sup>2</sup>. This tutorial serves an introduction to the two core modules of glm-py - `nml` and `simulation`. You will use glm-py to model Sparkling Lake for 2 years (1980-04-15 to 1982-04-15)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't already, install glm-py using `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install glm-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a GLM `.nml` file\n",
    "\n",
    "To begin, start by importing the `nml` module from `glmpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glmpy import nml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `nml` module provides a set of classes to construct GLM's namelist file (`.nml`).  A `.nml` file is divided into multiple \"blocks\" that configure specific aspects of the model, e.g., the `&morphometry` block defines morphometry of the water body. The structure of a `.nml` file is shown below for the four minimum required blocks (`...` indicates that the block contains more parameters than shown):\n",
    "\n",
    "```\n",
    "&glm_setup\n",
    "  sim_name = 'GLMSimulation'\n",
    "  ...\n",
    "/\n",
    "&morphometry\n",
    "  lake_name = 'my_lake'\n",
    "  ...\n",
    "/\n",
    "&time\n",
    "  timefmt = 3\n",
    "  ...\n",
    "/\n",
    "&init_profiles\n",
    "  lake_depth = 10\n",
    "  ...\n",
    "/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model setup\n",
    "\n",
    "GLM simulates the dynamics of a water body by dividing it into a vertically stacked series of layers. The compulsory `&glm_setup` block defines the structure of these layers, e.g., the maximum number of layers, the minimum layer volume, and the minimum and maximum layer thicknesses. To configure the `&glm_setup` parameters for Sparkling Lake, you would typically write a `.nml` file that contains the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "&glm_setup \n",
    "   sim_name = 'Sparkling Lake'\n",
    "   max_layers = 500\n",
    "   min_layer_vol = 0.5\n",
    "   min_layer_thick = 0.15\n",
    "   max_layer_thick = 0.5\n",
    "   density_model = 1\n",
    "   non_avg = .true.\n",
    "/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using glm-py, you instead configure the `&glm_setup` block by using the `NMLGLMSetup` class from the `nml` module. Each model parameter of the `&glm_setup` block has a corresponding attribute in the `NMLGLMSetup` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_setup = nml.NMLGLMSetup(\n",
    "    sim_name='Sparkling Lake',\n",
    "    max_layers=500,\n",
    "    min_layer_vol=0.5,\n",
    "    min_layer_thick=0.15,\n",
    "    max_layer_thick=0.5,\n",
    "    density_model=1,\n",
    "    non_avg=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach offers a number of advantages over editing a raw `.nml` file:\n",
    "\n",
    "- Explicit type hinting for parameter types\n",
    "- Native Python syntax\n",
    "- Error checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, these parameters can also be defined in a dictionary and set as class attributes using the `set_attributes()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_setup = nml.NMLGLMSetup()\n",
    "\n",
    "glm_setup_attrs = {\n",
    "    'sim_name': 'Sparkling Lake',\n",
    "    'max_layers': 500,\n",
    "    'min_layer_vol': 0.5,\n",
    "    'min_layer_thick': 0.15,\n",
    "    'max_layer_thick': 0.5,\n",
    "    'density_model': 1,\n",
    "    'non_avg': True\n",
    "}\n",
    "\n",
    "glm_setup.set_attributes(glm_setup_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the attributes are set, you can return a dictionary of the consolidated model parameters by calling the instance of the `NMLGLMSetup()` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_setup_parameters = glm_setup()\n",
    "print(glm_setup_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The call method provides an optional `check_errors` parameter. If set to `True`, glm-py will validate the model parameters and raise errors if non-compliance is detected. Note, `check_errors` is not fully implemented in glm-py `0.0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_setup(check_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixing and morphometry\n",
    "\n",
    "Next, let's set the parameters that control the mixing processes within Sparkling Lake. Just as `NMLGLMSetup` defines the `&glm_setup` block, we can configure the `&mixing` block using the `NMLMixing` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixing = nml.NMLMixing(\n",
    "    surface_mixing=1,\n",
    "    coef_mix_conv=0.2,\n",
    "    coef_wind_stir=0.402,\n",
    "    coef_mix_shear=0.2,\n",
    "    coef_mix_turb=0.51,\n",
    "    coef_mix_KH=0.3,\n",
    "    deep_mixing=2,\n",
    "    coef_mix_hyp=0.5,\n",
    "    diff=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the same for the `&morphometry` block - use the `NMLMorphometry` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphometry = nml.NMLMorphometry(\n",
    "    lake_name='Sparkling',\n",
    "    latitude=46.00881,\n",
    "    longitude=-89.69953,\n",
    "    bsn_len=901.0385,\n",
    "    bsn_wid=901.0385,\n",
    "    crest_elev=320.0,\n",
    "    bsn_vals=15,\n",
    "    H=[301.712, 303.018285714286, 304.324571428571,\n",
    "        305.630857142857, 306.937142857143, 308.243428571429,\n",
    "        309.549714285714, 310.856, 312.162285714286,\n",
    "        313.468571428571, 314.774857142857, 316.081142857143,\n",
    "        317.387428571429, 318.693714285714, 320, 321],\n",
    "    A=[0, 45545.8263571429, 91091.6527142857,\n",
    "        136637.479071429, 182183.305428571, 227729.131785714,\n",
    "        273274.958142857, 318820.7845, 364366.610857143,\n",
    "        409912.437214286, 455458.263571429, 501004.089928571,\n",
    "        546549.916285714, 592095.742642857, 637641.569, 687641.569]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the remaining blocks\n",
    "\n",
    "There are up to 14 configurable blocks in the GLM namelist file - setting each will take some time! Let's speed up the process by importing a JSON file that contains the parameters for the remaining blocks. We'll use the `JSONReader` class from the `glm_json` module to extract the relevant parameters from each respective block. Download the JSON file to your working directory using `curl`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://raw.githubusercontent.com/WET-tool/glm-py/main/notebooks/glmpy-demo/sparkling-nml.json --output sparkling-nml.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now import the `glm_json` module and initalise the `JSONReader` class by passing in the file path of the JSON file we just downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glmpy import glm_json\n",
    "\n",
    "my_json_file = glm_json.JSONReader(\"sparkling-nml.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's extract the parameters for the `&meteorology` block using the `get_nml_parameters()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorology_attrs = my_json_file.get_nml_parameters(\"&meteorology\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at what `meteorology_attrs` contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(meteorology_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a dictionary containing all parameters for the `&meteorology` block. Let's\n",
    "pass these to the `NMLMeteorology` class with the `set_attributes()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorology = nml.NMLMeteorology()\n",
    "meteorology.set_attributes(meteorology_attrs)\n",
    "print(meteorology())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy! But before we go any futher, look closely at the `meteo_fl` parameter - what's `bcs/nldas_driver.csv`? This is a path to a CSV that contains boundary condition data for Sparkling Lake, e.g., daily rainfall, wind speed, and air temperature. You'll need this file to run the model. Let's download it with `curl` and place it in sub-directory called `bcs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir bcs\n",
    "!curl https://raw.githubusercontent.com/WET-tool/glm-py/main/notebooks/glmpy-demo/bcs/nldas_driver.csv --output bcs/nldas_driver.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's setup the remaining blocks:  `&output`, `&init_profiles`, `&time`, `&bird_model`, `&light`, `&sediment`. We'll use `get_nml_parameters` to return dictionaries of parameters that will set the attributes of the corresponding `nml.NML*` classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_attrs=my_json_file.get_nml_parameters(\"&output\")\n",
    "init_profiles_attrs=my_json_file.get_nml_parameters(\"&init_profiles\")\n",
    "time_attrs=my_json_file.get_nml_parameters(\"&time\")\n",
    "light_attrs=my_json_file.get_nml_parameters(\"&light\")\n",
    "bird_model_attrs=my_json_file.get_nml_parameters(\"&bird_model\")\n",
    "sediment_attrs=my_json_file.get_nml_parameters(\"&sediment\")\n",
    "wq_setup_attrs=my_json_file.get_nml_parameters(\"&wq_setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now initialise the respective classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = nml.NMLOutput()\n",
    "init_profiles = nml.NMLInitProfiles()\n",
    "time = nml.NMLTime()\n",
    "light = nml.NMLLight()\n",
    "bird_model = nml.NMLBirdModel()\n",
    "sediment = nml.NMLSediment()\n",
    "wq_setup = nml.NMLWQSetup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And set the attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.set_attributes(output_attrs)\n",
    "init_profiles.set_attributes(init_profiles_attrs)\n",
    "time.set_attributes(time_attrs)\n",
    "light.set_attributes(light_attrs)\n",
    "bird_model.set_attributes(bird_model_attrs)\n",
    "sediment.set_attributes(sediment_attrs)\n",
    "wq_setup.set_attributes(wq_setup_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're want to find out more about the attributes for each block, check out glm-py's documentation website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the namelist file\n",
    "\n",
    "We now have the attributes set for each block. Let's combine them to create the `.nml` file. First, create an instance of the `NML` class. Then pass in the dictionaries of consolidated parameters, i.e., from `glm_setup()`, `mixing()`, `morphometry()`, etc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nml = nml.NML(\n",
    "  glm_setup=glm_setup(),\n",
    "  mixing=mixing(),\n",
    "  morphometry=morphometry(),\n",
    "  time=time(),\n",
    "  output=output(),\n",
    "  init_profiles=init_profiles(),\n",
    "  meteorology=meteorology(),\n",
    "  bird_model=bird_model(),\n",
    "  light=light(),\n",
    "  sediment=sediment()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use the `write_nml()` method to save the `.nml` to your working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nml.write_nml(nml_file_path='glm3.nml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model\n",
    "\n",
    "Model configuration is now complete! To run our Sparkling Lake simulation, import the `simulation` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glmpy import simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to specify the location of any files that we'll use in the simulation. For Sparkling Lake, that's just your newly created `glm3.nml` and the meterological boundary condition file `nldas_driver.csv`. These will be defined in a dictionary where the key is the filename and the value is the file path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    \"glm3.nml\": \"glm3.nml\",\n",
    "    \"nldas_driver.csv\": \"bcs/nldas_driver.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now pass this dictionary to a new instance of the `GLMSim` class. `GLMSim` is used prepare a new directory of model inputs that we'll point GLM at . Set `api` to `False` to run the simulation locally and set `inputs_dir` to the name of the inputs directory that will be created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_sim = simulation.GLMSim(\n",
    "    input_files=files,\n",
    "    api=False,\n",
    "    inputs_dir=\"inputs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the `inputs` directory by calling the `.prepare_inputs()` method:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_dir = glm_sim.prepare_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now have a new directory that looks like this:\n",
    "\n",
    "```\n",
    "├── bcs\n",
    "│   └── nldas_driver.csv\n",
    "├── glm3.nml\n",
    "```\n",
    "\n",
    "Finally, run the simulation by calling the `.glm_run()` method and pass in the `inputs_dir` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_sim.glm_run(inputs_dir=inputs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You've now configured and run a GLM simulation entirely in Python. You should see a new sub-directory called `outputs` within the `inputs` directory that contains the model results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glm-py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
